#+BEGIN_EXPORT html
---
layout: post
title: SICP Lecture 1B - Procedures and Processes; The Substitution Model
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
#+END_EXPORT

/This lecture covers mostly \S1.2 of the textbook./

* The substitution model 

To effectively design procedures a model for the processes they generate is required - the
/substitution model/ is a simple model which will suffice to begin investigating this relationship.
The substitution model evaluates a combination as follows:
1) Evaluate the operator to get the procedure
2) Evaluate the operands to get arguments
3) Apply the procedure to the arguments:
   - Copy the body of the procedure, replacing the formal parameters with the values of the supplied
     arguments
   - Evaluate the resulting new body
this process is recursive and continues until primitives which can be evaluated directly are
reached.
As an example evaluating ~(sum-of-squares 3 4)~ using the substitution model would play out as in
listing\nbsp[[src:subst-model-example]], note: the order of operand evaluation is arbitrary and is /not
defined by the scheme standard/.

#+CAPTION: Evaluating a combination using the substitution model
#+NAME: src:subst-model-example
#+BEGIN_SRC scheme
  (sum-of-squares 3 4)
  (+ (square 3) (square 4))
  (+ (square 3) (* 4 4))
  (+ (square 3) 16)
  (+ (* 3 3) 16)
  (+ 9 16)
  25
#+END_SRC

** Normal-order evaluation

The example in listing\nbsp[[src:subst-model-example]] used /applicative-order/ evaluation, evaluating the
operator and operands immediately before applying the procedure - this is the approach used by
=scheme=.
Alternatively /normal-order/ evaluation only evaluates operands when their values are needed, as in
listing\nbsp[[src:subs-model-example-normal-order]]. 

#+CAPTION: Normal-order evaluation example
#+NAME: src:subs-model-example-normal-order
#+BEGIN_SRC scheme
  (sum-of-squares 3 4)
  (+ (square 3) (square 4))
  (+ (square 3) (* 4 4))
  (+ (* 3 3) (* 4 4))
  (+ (* 3 3) 16)
  (+ 9 16)
  25
#+END_SRC

Both normal- and applicative-order evaluation yield the same results /when procedure application can
be modelled by the substitution model/, however as there are efficiency benefits to the
applicative-order application this is the one used by the =scheme= interpreter.

** Special forms: conditionals

/Special forms/ don't obey the usual evaluation rules, take ~if~ for example
#+BEGIN_SRC scheme
  (if <predicate>
      <consequent>
      <alternative>)
#+END_SRC
under the regular evaluation rules both ~<consequent>~ and ~<alternative>~ would be evaluated in
addition to ~<predicate>~, this is undesirable - see problem 1.5 for an example why - instead the ~if~
special form is evaluated as:
1) Evaluate ~<predicate>~
2) IF true, evaluate ~<consequent>~ expression
3) Otherwise, evaluate ~<alternative>~ expression

The related ~cond~ is similarly a special form with its own rules of evaluation.

* Processes from procedures

The idea of modelling how procedures give rise to processes is to enable design of procedures that
yield efficient processes (for some measure of efficiency: speed, memory, ...), examples to
demonstrate this are given below.

** Example: P\eacute{}ano arithmetic

Given a way to increment and decrement a number by one (in scheme the ~1+~ and ~1-~ operators
respectively) addition of two numbers can be defined as in listing\nbsp[[src:peano+.scm]], yielding the
process shown in listing\nbsp[[src:peano+-example.scm]]. 
Note that here the ~1+~ and ~1-~ procedures are /below/ the level of abstraction considered and are
treated as primitive.

#+CAPTION: Implementing addition in P\eacute{}ano arithmetic
#+NAME: src:peano+.scm
#+BEGIN_SRC scheme
  (define (peano+ x y)
    (if (= x 0)
        y
        (peano+ (1- x) (1+ y))))
#+END_SRC

#+CAPTION: Evaluating $3 + 4$ with P\eacute{}ano arithmetic
#+NAME: src:peano+-example.scm
#+BEGIN_SRC scheme
  (peano+ 3 4)
  (peano+ (1- 3) (1+ 4))
  (peano+ 2 5)
  (peano+ (1- 2) (1+ 5))
  (peano+ 1 6)
  (peano+ (1- 1) (1+ 6))
  (peano+ 0 7)
  7
#+END_SRC

A similar, but very subtly different, implementation of addition is given in
listing\nbsp[[src:peano+-2.scm]]. 
As can be seen ~peano+-2~ is nearly identical to the former definition, however the process it evolves
in listing\nbsp[[src:peano+-2-example.scm]] is significantly different.

#+CAPTION: Alternative implemenation of addition in P\eacute{}ano arithmetic
#+NAME: src:peano+-2.scm
#+BEGIN_SRC scheme
  (define (peano+-2 x y)
    (if (= x 0)
        y
        (1+ (peano+-2 (1- x) y))))
#+END_SRC

#+CAPTION: Evaluating $3 + 4$ with alternative P\eacute{}ano arithmetic implementaion
#+NAME: src:peano+-2-example.scm
#+BEGIN_SRC scheme
  (peano+-2 3 4)
  (1+ (peano+-2 2 4))
  (1+ (1+ (peano+-2 1 4)))
  (1+ (1+ (1+ (peano+-2 0 4))))
  (1+ (1+ (1+ 4)))
  (1+ (1+ 5))
  (1+ 6)
  7
#+END_SRC

Both approaches follow a common principle of reducing a problem to a simpler, base case for which
the answer is known, here $x\rightarrow0$.
Each implementation also involves a number of steps proportional to the input ~x~ performing
$\mathcal{O}\left(x\right)$ work.
The major difference is the work deferred by ~peano+-2~ building up a series of increments to be
performed once the base case is reached, the width of each line is in some sense the amount of stuff
the computer must remember, ~peano+~ is an /iteration/ requiring constant memory
$\mathcal{O}\left(1\right)$ whilst ~peano+-2~ has $\mathcal{O}\left(x\right)$ memory requirements and
is thus a (linear) /recursion/.[fn:1]
A key difference is that an iteration has /explicit state/ stored in its variables - it can be stopped
and restarted as if nothing happened - whereas recursions store /implicit state/ in the process.

** Designing procedures for recursive processes

The above examples are all recursively-defined algorithms, giving rise to either recursive or
iterative processes, in the case of recursive processes their designs all follow a similar pattern
1) /Wishful thinking/ - assume that a method exists for solving a smaller/simpler version of the
   problem.
2) /Decomposing the problem/ - take the problem and split it into a combination of simple operations
   and the solution to the smaller problem. This requires some ingenuity.
3) /Identifying the "smallest" problem/ - this problem is either non-decomposable or sufficiently
   small that is solved directly.
This results in a program design that tests the input, applying either the /recursive case/ or the
/base case/ when the smallest input is reached.

Another well known recursive algorithm is calculating the factorial
\begin{equation}
  n! =
  \begin{cases}
    n \left( n - 1 \right)! & n > 1 \\
    1 & \mbox{otherwise}
  \end{cases}
\end{equation}
as can be seen it consists of a test resulting in either the application of a simple procedure
(multiplication) to a smaller version of the problem $\left( n - 1 \right)!$, or a base case which
immediately returns its solution /i.e./ $1$.

Defining a procedure for a recursive process follows relatively trivially following the mathematical
definition 
#+BEGIN_SRC scheme
  (define (fact n)
    (if (> n 1)
        (* n (fact (- n 1)))
        1))
#+END_SRC
which as can be seen follows the above pattern: /assume/ that there is a solution for the smaller
problem ~(fact (- n 1))~; use this to solve the original problem with simple operations; test for the
base case where we can solve directly $1! = 1$.

** Designing procedures for iterative processes

The design of iterative processes requires identifying how to accumulate partial results combined
with an initialisation step to start the process.
This can be visualised as creating a table where each row is determined from the previous row(s), /e.g./

| Step | Result               |
|------+----------------------|
| $0$  | $x_0$                 |
| $1$  | $f\left( x_0 \right)$ |
| ...  | ...                  |

Applying this approach to the factorial it can be seen it is accumulating a series of products, /i.e./
\begin{equation}
  \begin{split}
    n! &= n \times \left( n - 1 \right) \times \ldots \times 1 \\
    &= \left( n \times \left( n - 1 \right) \right) \times \ldots \times 1
  \end{split}
\end{equation}
by storing the running product, no deferred operations are necessary, yielding an iterative process!
An example implementation is given below:
#+BEGIN_SRC scheme
  (define (fact n)
    (define (fact-iter product step)
      (if (> step n)
          product
          (fact-iter (* product step)
                     (+ step 1))))
    (fact-iter 1 1))
#+END_SRC

#+RESULTS:
: #<unspecified>

Note that compared to the recursive process which followed almost directly from the mathematical
definition, designing the procedure for an iterative process required additional consideration of
the problem.

*** Exercise: An iterative Fibonacci process

A classic example of recursive procedures and processes are the Fibonacci numbers
\begin{equation*}
  Fib\left(n\right) =
  \begin{cases}
    0 & n = 0 \\
    1 & n = 1 \\
    Fib\left(n - 2\right) + Fib\left(n - 1\right) & \mbox{otherwise}
  \end{cases}
\end{equation*}
listing\nbsp[[src:fib.scm]] translates this almost directly into =scheme=.
The process this evolves is /tree recursive/ - as can be seen ~(fib n)~ requires evaluating ~(fib (- n
1))~ and ~(fib (-n 2))~, ~(fib (- n 1))~ requires evaluating ~(fib (- n 2))~ and so on - resulting in an
exponential growth in work (in fact evaluating ~(fib n)~ requires
$\mathcal{O}\left(Fib\left(n\right)\right)$ work) - the memory requirements can be determined by
examining the length of the longest branch, here memory is $\mathcal{O}\left(n\right)$.

#+CAPTION: Recursive implementation of $Fib\left(n\right)$
#+NAME: src:fib.scm
#+BEGIN_SRC scheme
  (define (fib n)
    (if (< n 2)
        n
        (+ (fib (- n 1)
                (- n 2)))))
#+END_SRC

An iterative Fibonacci process would evaluate ~(fib n)~ in $\mathcal{O}\left(1\right)$ space.

For the general case the new value can be computed from the two previous values, so an iterative
process requires storing these two pieces of information in addition to the counter to determine
when to stop, my implementation is given in listing\nbsp[[src:fib-iter.scm]].

#+CAPTION: Iterative implementation of $Fib\left(n\right)$
#+NAME: src:fib-iter.scm
#+BEGIN_SRC scheme
  (define (fib n)
    (define (fib-iter ctr f1 f2)
      (cond ((= ctr n)
             (+ f1 f2))
            (else
             (fib-iter (1+ ctr) (+ f1 f2) f1))))
    (cond ((= n 0)
           0)
          ((= n 1)
           1)
          (else
           (fib-iter 1 1 0))))
#+END_SRC

The textbook implementation in listing\nbsp[[src:fib-iter-textbook.scm]] is more elegant, handling the base
cases automatically.

#+CAPTION: Textbook iterative implementation of $Fib\left(n\right)$
#+NAME: src:fib-iter-textbook.scm
#+BEGIN_SRC scheme
  (define (fib n)
    (define (fib-iter ctr f1 f2)
      (if (= ctr 0)
          f2
          (fib-iter (1- ctr) (+ f1 f2) f1)))
    (fib-iter n 1 0))
#+END_SRC

In addition to being $\mathcal{O}\left(1\right)$ in space the iterative process is also
$\mathcal{O}\left(n\right)$ in time, resulting in significant computational savings for $n\rightarrow\infty$.
Whilst the tree-recursive process is computationally inefficient they are useful due to the ease of
implementation, the iterative process required effort up front to develop.[fn:2]

** Formal proofs

/This comes from the 3^{rd} handout of the lecture notes./

It is important to be able to have confidence in the results returned by a program - designing a
procedure that efficiently computes the wrong answer is not very useful!
One approach would be to simply test the program, however considering the range of possible inputs
would require /exhaustive/ testing to show that the program won't fail for any (valid) input.
Alternatively, if a program can be /proven/ correct it will work for all (valid) inputs.

*** Proof by induction

To demonstrate this, consider the predicate
\begin{equation}
  P\left(n\right) : \sum^n_{l=0} 2^l = 2^{n+1} - 1
\end{equation}
to prove this is true for all possible inputs requires showing it holds for some base case, /e.g./
$n=0$:
\begin{equation}
  P\left( 0 \right) : 2^0 = 2^1 - 1 = 1 \Rightarrow P\left( 0 \right) = T
\end{equation}
Then it needs to be shown that the truth of the base case proves the truth of all other cases
\begin{equation}
  \begin{split}
    P\left(n+1\right) &: \sum^{n+1}_{l=0} 2^l &= \sum^n_{l=0} 2^l + 2^{n+1} \\
    & &= \left( 2^{n+1} - 1 \right) + 2^{n+1} \\
    & & = 2^{n+2} - 1 = 2^{\left(n + 1\right) + 1} - 1 \\
    \therefore \forall n>=0 &: P\left( n \right) &
  \end{split}
\end{equation}
because $P\left(n\right)$ holds for the base case $n=0$ and for the next case $n+1$ it follows that
it holds for all $n>=0$.

*** Example: factorial

Returning to the factorial, the proof by induction can be demonstrated for a program.
\begin{equation}
  \begin{split}
    P(n)&:(define\ (fact\ n) \\
    &\qquad (if\ (=\ n\ 1) \\
    &\qquad\qquad 1 \\
    &\quad\qquad (*\ n\ (fact\ (-\ n\ 1)))))
  \end{split}
\end{equation}
For the base case $n=1$ $(fact\ 1)$ returns $1=1!$, therefore $P\left(1\right)=T$.
To show it works for /all/ positive integers:
\begin{equation}
  \begin{split}
    (fact\ (+\ n\ 1)) &= (*\ (+\ n\ 1)\ (fact\ n)) \\
    &= (*\ (+\ n\ 1)\ n!) = (n + 1)!
  \end{split}
\end{equation}
where it has been assumed that $(fact\ n) = n!$, as proven by the base case it can then be induced
that $\forall{}n>0:P\left(n\right)$.

As this example shows, induction is a basis for understanding, analysing and proving the correctness
of recursive procedure definitions.
It can also be used in the design of programs - given a new problem:
1) Identify base case and solution
2) Turn to the issue of breaking the problem int a simpler version, assuming that the code will solve
   the simpler version
3) Use that to construct the inductive step - /how/ to solve the full problem
/c.f./ the procedures described in \S[[Designing procedures for recursive processes]] and \S[[Designing
procedures for iterative processes]]. 

* Orders of growth
* Footnotes

[fn:2] Could a /sufficiently smart/ compiler transform an easy to specify tree-recursive procedure
into a more efficient one producing the same result?

[fn:1] Note that both procedure definitions are recursive yet the processes they yield are an
iteration and a recursion, respectively.
